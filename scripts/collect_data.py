"""
=============================================================================
SCRIPT DE COLLECTE DE DONN√âES - OPENFOODFACTS
=============================================================================
Ce script r√©cup√®re des donn√©es de produits alimentaires depuis l'API
OpenFoodFacts et les stocke dans MongoDB.

OpenFoodFacts est une base de donn√©es ouverte et collaborative sur
les produits alimentaires du monde entier.

UTILISATION :
    python scripts/collect_data.py                    # Collecte 300 produits
    python scripts/collect_data.py --count 500        # Collecte 500 produits
    python scripts/collect_data.py -c beverages       # Collecte seulement les boissons
    python scripts/collect_data.py --output data.json # Sauvegarde en JSON

FONCTIONNEMENT :
1. Parcourt les cat√©gories de produits d√©finies dans settings.py
2. R√©cup√®re des produits via l'API OpenFoodFacts
3. V√©rifie la validit√© des donn√©es (champs obligatoires pr√©sents)
4. √âlimine les doublons (bas√© sur le code-barres)
5. Stocke les donn√©es brutes dans MongoDB (collection products_raw)
=============================================================================
"""

import argparse  # Pour parser les arguments en ligne de commande
import json      # Pour lire/√©crire des fichiers JSON
import sys
import time      # Pour les d√©lais entre requ√™tes
from datetime import datetime
from pathlib import Path
from typing import Optional, List

import requests  # Librairie pour faire des requ√™tes HTTP
from loguru import logger  # Librairie de logging avanc√©e

# Ajouter le chemin racine au path Python pour pouvoir importer nos modules
ROOT_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT_DIR))

# Configuration des logs : format color√© avec timestamp
# logger.remove() enl√®ve le handler par d√©faut
# logger.add() ajoute notre propre format
logger.remove()
logger.add(sys.stdout, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>", level="INFO")


class Collector:
    """
    Classe responsable de la collecte de donn√©es depuis OpenFoodFacts.
    
    Elle g√®re :
    - Les requ√™tes HTTP vers l'API avec retry en cas d'erreur
    - La validation des donn√©es re√ßues
    - La d√©duplication des produits
    - Les statistiques de collecte
    
    Attributs:
        page_size: Nombre de produits par page de r√©sultats
        delay: D√©lai entre chaque requ√™te (en secondes)
        timeout: Timeout des requ√™tes HTTP (en secondes)
        max_retries: Nombre de tentatives en cas d'erreur
        stats: Dictionnaire de statistiques de collecte
        session: Session HTTP requests (r√©utilise les connexions)
    """
    
    # Champs obligatoires : un produit DOIT avoir ces champs
    # pour √™tre consid√©r√© comme valide
    REQUIRED_FIELDS = ["code", "product_name"]
    
    def __init__(self, page_size: int = 100, delay: float = 1.0, timeout: int = 30, max_retries: int = 3):
        """
        Initialise le collecteur avec ses param√®tres.
        
        Args:
            page_size: Nombre de produits par requ√™te (max 100 pour OpenFoodFacts)
            delay: Pause entre les requ√™tes pour ne pas surcharger l'API
            timeout: Temps maximum d'attente pour une r√©ponse
            max_retries: Nombre de tentatives en cas d'√©chec
        """
        self.page_size = page_size
        self.delay = delay
        self.timeout = timeout
        self.max_retries = max_retries
        
        # Statistiques de collecte (pour le rapport final)
        self.stats = {
            "collected": 0,       # Produits collect√©s avec succ√®s
            "errors": 0,          # Erreurs totales
            "timeouts": 0,        # Timeouts (serveur trop lent)
            "invalid_format": 0,  # R√©ponses JSON invalides
            "missing_data": 0     # Produits avec donn√©es manquantes
        }
        
        # Session HTTP persistante (optimisation des performances)
        # R√©utilise les connexions TCP au lieu d'en cr√©er une par requ√™te
        self.session = requests.Session()
        # User-Agent : identifie notre script aupr√®s de l'API
        self.session.headers.update({"User-Agent": "TP_BDD_Collector/1.0"})
    
    def _request(self, url: str, params: dict) -> Optional[dict]:
        """
        Effectue une requ√™te HTTP GET avec retry en cas d'erreur.
        
        Cette m√©thode est robuste : elle r√©essaie plusieurs fois
        en cas de timeout ou d'erreur r√©seau, avec un d√©lai croissant.
        
        Args:
            url: URL de l'API √† appeler
            params: Param√®tres de la requ√™te (pass√©s en query string)
            
        Returns:
            dict: R√©ponse JSON pars√©e, ou None en cas d'erreur d√©finitive
        """
        for attempt in range(1, self.max_retries + 1):
            try:
                # Effectuer la requ√™te GET
                response = self.session.get(url, params=params, timeout=self.timeout)
                # Lever une exception si le code HTTP indique une erreur (4xx, 5xx)
                response.raise_for_status()
                # Parser et retourner le JSON
                return response.json()
                
            except requests.exceptions.Timeout:
                # Le serveur n'a pas r√©pondu √† temps
                self.stats["timeouts"] += 1
                self.stats["errors"] += 1
                logger.warning(f"Timeout (tentative {attempt}/{self.max_retries})")
                if attempt < self.max_retries:
                    # Attendre de plus en plus longtemps entre les tentatives
                    # (backoff exponentiel : 2s, 4s, 6s, ...)
                    time.sleep(attempt * 2)
                    
            except json.JSONDecodeError:
                # La r√©ponse n'est pas du JSON valide
                self.stats["invalid_format"] += 1
                self.stats["errors"] += 1
                logger.warning("Format JSON invalide")
                return None  # Pas de retry, c'est une erreur de donn√©es
                
            except requests.exceptions.RequestException as e:
                # Autres erreurs HTTP (connexion refus√©e, DNS, etc.)
                self.stats["errors"] += 1
                logger.error(f"Erreur requ√™te: {e}")
                if attempt < self.max_retries:
                    time.sleep(attempt * 2)
                    
        # Toutes les tentatives ont √©chou√©
        return None
    
    def _is_valid(self, product: dict) -> bool:
        """
        V√©rifie si un produit a les champs obligatoires.
        
        Un produit sans code-barres ou sans nom n'est pas exploitable.
        
        Args:
            product: Donn√©es du produit √† valider
            
        Returns:
            bool: True si le produit est valide, False sinon
        """
        for field in self.REQUIRED_FIELDS:
            # V√©rifier que le champ existe et n'est pas vide
            if not product.get(field):
                return False
        return True
    
    def collect(self, target_count: int = 300, categories: Optional[List[str]] = None, country: str = "france") -> List[dict]:
        """
        Collecte des produits depuis OpenFoodFacts.
        
        Parcourt les cat√©gories une par une et r√©cup√®re des produits
        jusqu'√† atteindre l'objectif (target_count).
        
        Args:
            target_count: Nombre de produits √† collecter (objectif minimum)
            categories: Liste des cat√©gories √† parcourir (d√©faut: MAIN_CATEGORIES)
            country: Pays des produits √† r√©cup√©rer (d√©faut: France)
            
        Returns:
            List[dict]: Liste des produits collect√©s (donn√©es brutes)
        """
        # Import des constantes depuis la config
        from config.settings import MAIN_CATEGORIES, OPENFOODFACTS_SEARCH_URL
        
        # Utiliser les cat√©gories par d√©faut si non sp√©cifi√©es
        if categories is None:
            categories = MAIN_CATEGORIES
        
        collected = []  # Liste des produits collect√©s
        seen_codes = set()  # Ensemble des codes-barres d√©j√† vus (pour d√©duplication)
        
        # Calculer combien de produits r√©cup√©rer par cat√©gorie
        # On prend un peu plus que n√©cessaire pour compenser les doublons
        products_per_category = max(target_count // len(categories) + 10, 50)
        
        logger.info(f"üéØ Objectif: {target_count} produits")
        
        # === BOUCLE SUR LES CAT√âGORIES ===
        for category in categories:
            # Arr√™ter si on a atteint l'objectif
            if len(collected) >= target_count:
                break
            
            logger.info(f"üìÇ Cat√©gorie: {category}")
            page = 1  # Num√©ro de page (pagination de l'API)
            category_count = 0  # Compteur pour cette cat√©gorie
            
            # === BOUCLE DE PAGINATION ===
            while category_count < products_per_category and len(collected) < target_count:
                # Construire les param√®tres de la requ√™te de recherche
                params = {
                    "action": "process",      # Action de recherche
                    "json": 1,                # R√©ponse en JSON
                    "page_size": self.page_size,  # Produits par page
                    "page": page,             # Num√©ro de page
                    # Filtre par cat√©gorie
                    "tagtype_0": "categories",
                    "tag_contains_0": "contains",
                    "tag_0": category,
                    # Filtre par pays
                    "tagtype_1": "countries",
                    "tag_contains_1": "contains",
                    "tag_1": country
                }
                
                # Effectuer la requ√™te
                data = self._request(OPENFOODFACTS_SEARCH_URL, params)
                if not data or not isinstance(data, dict):
                    break  # Erreur ou r√©ponse invalide
                
                products = data.get("products", [])
                if not products:
                    break  # Plus de produits dans cette cat√©gorie
                
                # === TRAITEMENT DE CHAQUE PRODUIT ===
                for raw_product in products:
                    # V√©rifier qu'on n'a pas atteint l'objectif
                    if len(collected) >= target_count:
                        break
                    
                    # V√©rifier que c'est bien un dictionnaire
                    if not isinstance(raw_product, dict):
                        self.stats["invalid_format"] += 1
                        continue
                    
                    # R√©cup√©rer le code-barres pour la d√©duplication
                    code = raw_product.get("code", "")
                    if code in seen_codes:
                        continue  # Produit d√©j√† collect√©, on saute
                    
                    # Valider les champs obligatoires
                    if not self._is_valid(raw_product):
                        self.stats["missing_data"] += 1
                        continue
                    
                    # Produit valide ! On l'ajoute √† la collection
                    collected.append(raw_product)
                    seen_codes.add(code)  # Marquer comme vu
                    category_count += 1
                    self.stats["collected"] += 1
                
                # Passer √† la page suivante
                page += 1
                # Attendre un peu pour √™tre poli avec l'API
                time.sleep(self.delay)
        
        # Afficher le r√©sum√© de la collecte
        logger.info(f"‚úÖ Collect√©s: {self.stats['collected']} | Erreurs: {self.stats['errors']} | Timeouts: {self.stats['timeouts']} | Format invalide: {self.stats['invalid_format']} | Donn√©es manquantes: {self.stats['missing_data']}")
        return collected
    
    def save_to_mongodb(self, raw_products: List[dict]) -> int:
        """
        Sauvegarde les produits collect√©s dans MongoDB.
        
        Utilise le MongoDBManager pour ins√©rer les produits dans
        la collection products_raw. Les doublons sont ignor√©s.
        
        Args:
            raw_products: Liste des produits √† sauvegarder
            
        Returns:
            int: Nombre de produits effectivement ins√©r√©s
        """
        from src.database.mongodb_manager import MongoDBManager
        
        # Utiliser le context manager pour g√©rer la connexion
        with MongoDBManager() as mongo:
            count = mongo.insert_raw_documents_batch(raw_products, source="openfoodfacts")
            logger.info(f"üíæ {count} documents ins√©r√©s dans MongoDB (RAW)")
            return count


# =============================================================================
# POINT D'ENTR√âE DU SCRIPT
# =============================================================================

def main():
    """
    Fonction principale du script de collecte.
    
    Parse les arguments en ligne de commande et lance la collecte.
    """
    # D√©finir les arguments accept√©s par le script
    parser = argparse.ArgumentParser(description="Collecte OpenFoodFacts")
    parser.add_argument("--count", "-n", type=int, default=300, 
                        help="Nombre minimum de produits (d√©faut: 300)")
    parser.add_argument("--categories", "-c", nargs="+", default=None, 
                        help="Cat√©gories √† collecter")
    parser.add_argument("--country", default="france", 
                        help="Pays cible (d√©faut: france)")
    parser.add_argument("--no-mongodb", action="store_true", 
                        help="Ne pas sauvegarder dans MongoDB")
    parser.add_argument("--output", "-o", type=str, default=None, 
                        help="Fichier JSON de sortie")
    
    # Parser les arguments
    args = parser.parse_args()
    
    # Cr√©er le collecteur avec les param√®tres par d√©faut
    collector = Collector()
    
    try:
        # Lancer la collecte
        products = collector.collect(
            target_count=args.count, 
            categories=args.categories, 
            country=args.country
        )
        
        # V√©rifier qu'on a bien des produits
        if not products:
            logger.error("Aucun produit collect√©!")
            sys.exit(1)
        
        # Si un fichier de sortie est sp√©cifi√©, sauvegarder en JSON
        if args.output:
            # G√©rer les chemins relatifs et absolus
            output_path = Path(args.output) if Path(args.output).is_absolute() else ROOT_DIR / args.output
            output_path.parent.mkdir(parents=True, exist_ok=True)
            # √âcrire le fichier JSON avec indentation pour lisibilit√©
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(products, f, ensure_ascii=False, indent=2)
            logger.info(f"üíæ Sauvegard√© dans: {output_path}")
        
        # Sauvegarder dans MongoDB (sauf si --no-mongodb)
        if not args.no_mongodb:
            try:
                collector.save_to_mongodb(products)
            except Exception as e:
                logger.warning(f"MongoDB non disponible: {e}")
        
        logger.success(f"‚úÖ Collecte termin√©e: {len(products)} produits")
        
    except KeyboardInterrupt:
        # L'utilisateur a appuy√© sur Ctrl+C
        logger.warning("Collecte interrompue")
        sys.exit(1)


if __name__ == "__main__":
    main()
